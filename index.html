<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ali Asgarov</title>

    <meta name="author" content="Ali Asgarov">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ali Asgarov
                </p>
                <p>I'm a Ph.D. student at the department of computer science at <a href="https://www.vt.edu/">Virginia Tech</a> , Blacksburg, VA, United States. I work in computer vision and natural language processing, with a focus on multimodal learning and vision-language models. Before joining Virginia Tech, I completed an M.Sc. in Computer Science at <a href="https://gwu.edu/">George Washington University</a>.
                </p>
                <p>
                   At Virginia Tech, I am working under the guidance of  <a href="https://people.cs.vt.edu/chris/">Dr. Chris Thomas</a> on advancing video-language understanding with cross-modal reasoning. In the past,  I have been fortunate to collaborate with <a href="https://scholar.google.com/citations?hl=en&user=T8-BGRsAAAAJ&view_op=list_works&sortby=pubdate">Dr. Rebecca Hwa</a> at George Washington University and <a href="https://samirrustamov.com/en/">Dr. Samir Rustamov</a> on cross-modal information retrieval across image, text, video, and audio.
                </p>

                <p>
                  I am associated with the <a href="https://sanghani.cs.vt.edu/people/our-team/students/ali-asagrov.html">Sanghani Center for Artificial Intelligence and Data Analytics</a>.
               </p> 
 
                <p style="text-align:center">
                  <a href="mailto:aliasgarov@vt.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/resume_aa.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=IwsCoQwAAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/aliasgerovs">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/aliasgerovs/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ali-asgarov/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:29%;max-width:29%">
                <!-- <a href="images/avatar.jpg"> -->
                  <img 
                    style="width:90%; max-width:90%; object-fit: cover; border-radius: 5px;" 
                    alt="profile photo" 
                    src="images/avatar.jpg">
                </a>
              </td>              
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <!-- <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>. -->
                <!-- </p> -->
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<!-- Research -->
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <p style="font-weight:bold; margin:0;">Research</p>
          <hr>
          <p style="padding:0px;width:100%;vertical-align:middle">My research interests include:</p>
          <ul>
            <li><strong>Reasoning in vision-language models.</strong></li>
            <li><strong>Cross-modal retrieval across images, text, video, and audio.</strong></li>
            <li><strong>Structured information extraction from multimodal data.</strong></li>
            <li><strong>Knowledge representation for multimodal reasoning.</strong></li>
          </ul>
        </td>
      </tr>
    </tbody>
  </table>  


<!-- News -->
 
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:10px;width:100%;vertical-align:middle">
        <p style="font-weight:bold; margin:0;">News</p>
        <hr>
      </td>
    </tr>
  </tbody>
</table>
<table style="padding:10px;width:100%;border:0px;border-spacing:3px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>


          <!-- ITEM -->
      <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:rgb(0, 0, 0); display:inline; margin:0;">Oct. '25</p>
        </td>
        <td style="vertical-align:top;">
            One paper is under review at <strong><a href="https://aclrollingreview.org/">ACL ARR 2026</a></strong>.
        </td>
      </tr>


          <!-- ITEM -->
      <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:rgb(0, 0, 0); display:inline; margin:0;">Sep. '25</p>
        </td>
        <td style="vertical-align:top;">
            Our paper is accepted at  <strong><a href="https://2025.emnlp.org/">EMNLP 2025</a></strong>.
        </td>
      </tr>


          <!-- ITEM -->
      <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:rgb(0, 0, 0); display:inline; margin:0;">Aug. '25</p>
        </td>
        <td style="vertical-align:top;">
            One paper is under review at <strong><a href="https://mathai2025.github.io/">NeurIPS2025 MathAI</a></strong>.
        </td>
      </tr>

                <!-- ITEM -->
      <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:rgb(0, 0, 0); display:inline; margin:0;">June. '25</p>
        </td>
        <td style="vertical-align:top;">
            One paper is under review at <strong><a href="https://arxiv.org/abs/2509.16805">CHI 2026</a></strong>.
        </td>
      </tr>


            <!-- ITEM -->
      <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:rgb(0, 0, 0); display:inline; margin:0;">May. '25</p>
        </td>
        <td style="vertical-align:top;">
            Reviewer at <strong><a href="https://2025.emnlp.org/">EMNLP 2025</a></strong>.
        </td>
      </tr>


      <!-- ITEM -->
      <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:rgb(0, 0, 0); display:inline; margin:0;">Apr. '25</p>
        </td>
        <td style="vertical-align:top;">
            Reviewer at <strong><a href="https://dl.acm.org/journal/tist/indexing">ACM TIST</a></strong>.
        </td>
      </tr>

      <!-- ITEM -->
      <!-- <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:darkblue; display:inline; margin:0;">Mar. '25</p>
        </td>
        <td style="vertical-align:top;">
          One paper is under review for <strong>COLM2025</strong>.
        </td>
      </tr> -->
    <!-- ITEM -->
      
    <!-- ITEM -->
    <!-- <tr>
      <td style="width: 80px; vertical-align:top;">  
        <p style="color:darkblue; display:inline; margin:0;">Dec. '24</p>
      </td>
      <td style="vertical-align:top;">
        One paper is under review for <strong>CVPR2025</strong>.
      </td>
    </tr> -->
  <!-- ITEM -->

    <!-- ITEM -->
    <!-- <tr>
      <td style="width: 80px; vertical-align:top;">  
        <p style="color:rgb(20, 20, 27); display:inline; margin:0;">Oct. '24</p>
      </td>
      <td style="vertical-align:top;">
        Our paper <strong>ENTER</strong> was <strong>accepted</strong> as a <strong>spotlight paper</strong> at the Multimodal Reasoning Workshop, <a href="https://marworkshop.github.io/neurips24/"><strong>NeurIPS 2024</strong></a>.
      </td>
    </tr>

 -->

    <!-- ITEM -->
    <!-- <tr>
      <td style="width: 80px; vertical-align:top;">  
        <p style="color:darkblue; display:inline; margin:0;">Aug. '24</p>
      </td>
      <td style="vertical-align:top;">
        Started Ph.D. program in Computer Science at Virginia Tech.
      </td>
    </tr> -->
      <!-- ITEM -->
      <!-- <tr>
        <td style="width: 80px; vertical-align:top;">  
          <p style="color:darkblue; display:inline; margin:0;">Jul. '24</p>
        </td>
        <td style="vertical-align:top;">
          One paper is under review for <strong>COLING2025</strong>.
        </td>
      </tr> -->
    <!-- ITEM -->
    <!-- <tr>
      <td style="width: 80px; vertical-align:top;">  
        <p style="color:darkblue; display:inline; margin:0;">Apr. '24</p>
      </td>
      <td style="vertical-align:top;">
        Received Ph.D. offer from Virginia Tech in Computer Science.
      </td>
    </tr> -->
    <!-- ITEM -->
    <!-- <tr>
      <td style="width: 80px; vertical-align:top;">  
        <p style="color:darkblue; display:inline; margin:0;">Dec. '23</p>
      </td>
      <td style="vertical-align:top;">
        Graduated from George Washington University with a Master's degree in Computer Science.
      </td>
    </tr> -->
  </tbody>
</table>


<!-- Publications -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:10px;width:100%;vertical-align:middle">
        <p style="font-weight:bold; margin:0;">Publications</p>
        <hr>
      </td>
    </tr>
  </tbody>
</table>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <!-- PAPER 1 -->
    <tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
        <img src="images/bias.png" alt="PontTuset" style="width: 90%; height: auto; display: block; border: none;">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2509.16805">
          <papertitle>Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models</papertitle>
        </a>
        <br>
        MD Atabuzzaman, <u><strong>Ali Asgarov*</strong></u>, Chris Thomas
        <br>
        <p>We study multiple-choice question answering (MCQA) selection bias in large vision-language models and propose methods to benchmark and mitigate this bias, improving model robustness and fairness.</p>
        <p><strong><em>*The proposed bias mitigation method was created and implemented by this author.</em></strong></p> 
        <p>This paper was accepted at <a href="https://2025.emnlp.org/"><strong>EMNLP 2025</strong> (Main Conference) </a></p> 
      
      </td>
    </tr> 
  </tbody>
</table>



<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <!-- PAPER 1 -->
    <tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
        <img src="images/enter_method.png" alt="PontTuset" style="width: 90%; height: auto; display: block; border: none;">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2501.14194">
          <papertitle>ENTER: Event Based Interpretable Reasoning for VideoQA.</papertitle>
        </a>
        <br>
        Hammad Ayyubi, Junzhang Liu, <u><strong>Ali Asgarov </strong></u>, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Chia-Wei Tang, Zhecan James Wang, Hani Alomari, Md. Atabuzzaman, Xudong Lin, Naveen Reddy,  Shih-Fu Chang, Chris Thomas
        <br>
        <p>We introduce <strong>ENTER</strong>, an interpretable system for video question answering that uses event-graph representations to integrate visual data with transparent, structured reasoning, achieving high performance and enhanced explainability on complex, long-range questions.</p>
        <p>This paper was accepted and selected as a <strong style="color:rgb(0, 111, 0);">spotlight paper</strong> at the Multimodal Algorithmic Reasoning Workshop, <a href="https://marworkshop.github.io/neurips24/"><strong>NeurIPS 2024</strong></a></p>
      
      </td>
    </tr> 
  </tbody>
</table>




<p style="padding:10px;width:100%;vertical-align:middle">Please see my <a href="https://scholar.google.com/citations?user=IwsCoQwAAAAJ&hl">Google Scholar</a> page for an up-to-date list.</p>
        

          

<!-- Education -->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr>
      <td style="padding:10px;width:100%;vertical-align:middle">
        <p style="font-weight:bold; margin:0;">Education</p>
        <hr>
      </td>
    </tr>
  </tbody>
</table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <!-- School 1 - Virginia Tech -->
    <tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
        <img src="images/vt.png" alt="Virginia Tech" style="width: 90%; height: auto; display: block; border: none;">
      </td>
      <td width="75%" valign="middle">
        <b>Virginia Tech</b>
        <br> 08.2024 - Present
        <br> <b>PhD in Computer Science</b>
        <br> GPA: 4.0 / 4.0
        <br> Advisor: Dr. <a href="https://people.cs.vt.edu/chris/">Chris Thomas</a>
      </td>
    </tr>
    <!-- School 2 - George Washington University -->
    <tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
        <img src="images/gwu.png" alt="George Washington University" style="width: 90%; height: auto; display: block; border: none;">
      </td>
      <td width="75%" valign="middle">
        <b>George Washington University</b>
        <br> 08.2022 - 12.2023
        <br> <b>MSc. in Computer Science</b>
        <br> GPA: 3.76 / 4.00
        <br> Advisors: Dr. <a href="https://scholar.google.com/citations?hl=en&user=T8-BGRsAAAAJ&view_op=list_works&sortby=pubdate">Rebecca Hwa</a> & Dr. <a href="https://samirrustamov.com/en/">Samir Rustamov</a>
      </td>
    </tr>



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <p style="font-weight:bold; margin:0;">Honors &amp; Awards</p>
            <hr>
            <ul>
              <li><b>2022</b> - Awarded Pratt Fellowship, Virginia Tech</li>
              <li><b>2023</b> - State Program on Education of Azerbaijani Youth Abroad Scholarship</li>
              <li><b>2022</b> - 3x 1st Place, National AI Competition in ML Applications (2020-2022).</li>
              <li><b>2020</b> - Ranked among the top 15 teams at the III World Robot Olympiad in Gyor, Hungary</li>
              <li><b>2019</b> - Golden Medal at the III World Robot Olympiad in Azerbaijan</li>
              <li><b>2018</b> - Presidential Scholarship for Exceptional Academic Performance</li>
              <li><b>2017</b> - Scored 690 out of 700 on the University Entrance Exam</li>
              <li><b>2017</b> - High School Graduate with a Golden Medal, placing in the top 0.1% among 90,000 graduating students</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>


 <!-- Teaching -->

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <p style="font-weight:bold; margin:0;">Teaching</p>
            <hr>
            <ul>
              <li><b>CS3114:</b> - Data Structures & Algorithms, Spring 2025, Virginia Tech</li>
              <li><b>CS5644:</b> - Machine Learning with Big Data, Fall 2024, Virginia Tech</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>
    


    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=320&t=tt&d=E65_C3AqYzF5qtdeKwiF1WHsSq7W1i-A8JFHQARNRXA"></script>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;font-size:small;">
              The source for this website is from <a href="https://jonbarron.info/">here.</a>
            </p>
          </td>
        </tr>
      </tbody>
    </table>


          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
